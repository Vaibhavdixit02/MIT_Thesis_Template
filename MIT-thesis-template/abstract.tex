% From mitthesis package
% Version: 1.01, 2023/06/19
% Documentation: https://ctan.org/pkg/mitthesis
%
% The abstract environment creates all the required headers and footnote. 
% You only need to add the text of the abstract itself.
%
% Approximately 500 words or less; try not to use formulas or special characters
% If you don't want an initial indentation, do \noindent at the start of the abstract

This thesis develops novel computational and theoretical approaches for solving challenging continuous, nonlinear, and nonconvex optimization problems across statistics, machine learning, and optimal control. We make three primary contributions to address fundamental difficulties in non-convex optimization: First, we introduce Disciplined Geodesically Convex Programming (DGCP), which extends convexity verification to Riemannian manifolds and enables optimization on curved spaces with theoretical guarantees. We construct a comprehensive framework of rules and atoms for Cartan-Hadamard manifolds, with special attention to symmetric positive definite matrices. Second, we develop a GPU-accelerated hybrid optimization framework that combines the global exploration capability of Particle Swarm Optimization with the efficient local convergence of L-BFGS, demonstrating speedups on inverse problems with multiple local minima. Third, we propose an augmented Lagrangian method with stochastic inner optimizers such as Adam, bridging constrained optimization with modern machine learning techniques. Throughout, we emphasize practical implementation, providing optimized and composable libraries unified under the Optimization.jl ecosystem that makes these advanced methods accessible to practitioners across disciplines.